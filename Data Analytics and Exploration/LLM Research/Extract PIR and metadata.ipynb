{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7e707b-f7ea-4a0a-9edf-a2b5f9d8e581",
   "metadata": {},
   "source": [
    "This notebook is for developing the code for extracting metadata from the Prisma incident report (PIR) data. The notebook:\n",
    "\n",
    "* Loads the full set of PIRs, both labeled and unlabeled\n",
    "* Separates the labeled from the unlabeled PIRs\n",
    "* Defines a function that takes as input a prompt template, a set of labeled PIRs, and an unlabeled PIR to create a few-shot learning (FSL) prompt\n",
    "* Defines a function that takes as input a prompt and a LLM, and returns the model's output\n",
    "* Defines a function that parses the model output to produce structured metadata\n",
    "* Saves the resulting structured metadata.\n",
    "\n",
    "This notebook is for developing that code; once it is developed, it should be put into one or several .py script(s) so that it can be run on the Cluster without having a Jupyter session open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c242f9-7a5a-463b-938c-c59893eac367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from langchain import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ccbcd4e-aa90-4377-bc4d-542913de989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unlabeled PIRs (full)\n",
    "\"\"\"\n",
    "In its final form, the unlabeled PIRs should be in the format of a pandas dataframe,\n",
    "where one column (titled 'text') is the PIR, and 'near_miss' and 'any_harm' each have a column.\n",
    "\"\"\"\n",
    "\n",
    "# Read the full PIRs\n",
    "\n",
    "PIRs_full = pd.read_excel(\"PIRS_FULL.xlsx\",usecols=['Near_Miss', 'Any_Harm', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36e6f92-2fa9-4223-80bd-cbc5e064e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled PIRs\n",
    "\"\"\"\n",
    "In its final form, the labeled PIRs should be in the format of a pandas dataframe with four columns,\n",
    "where one column (titled 'text') is the PIR, and the other three columns are 'risks_challenges',\n",
    "'actions_strategies', and 'facilitators'.\n",
    "\"\"\"\n",
    "\n",
    "# Read the labeled PIRs\n",
    "\n",
    "PIRs_labeled = pd.read_excel(\"PIRS_LABELED.xlsx\", usecols=['Text', 'Risk_Challenge', 'Actions_Strategies', 'Facilitators'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9837df3-8361-4cb6-9e9f-12326d3a8781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labeled from unlabeled PIRs\n",
    "\"\"\"\n",
    "PIRs appearing in the labeled data should be dropped from the unlabeled data set.\n",
    "\"\"\"\n",
    "\n",
    "df = pd.merge(PIRs_full, PIRs_labeled, on =[\"Text\"], how = \"outer\", indicator = True)\n",
    "\n",
    "df2 = df.loc[df[\"_merge\"] == \"left_only\"].drop(\"_merge\", axis=1)\n",
    "\n",
    "PIRs_unlabeled = df2.drop(columns=['Risk_Challenge', 'Actions_Strategies','Facilitators', 'Near_Miss', 'Any_Harm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361d6001-7222-4422-906e-54ddc9fccf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the actions/strategies labeled PIRs\n",
    "\n",
    "labeled_pirs = PIRs_labeled[['Text','Actions_Strategies']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324df005-bd88-40e6-a68c-6288c241499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get five examples\n",
    "\n",
    "#Example 1\n",
    "ex1 = labeled_pirs.sample(n=1)\n",
    "ex1_text = ex1['Text']\n",
    "ex1_text = \"\".join(ex1_text)\n",
    "ex1_as = ex1['Actions_Strategies']\n",
    "ex1_as = ex1_as.to_csv(header = None, index=False)\n",
    "ex1_as = ex1_as.split('\\n')\n",
    "\n",
    "ex1_as = ','.join(ex1_as)\n",
    "ex1_as = ex1_as.replace(',,',',')\n",
    "ex1_as = ex1_as[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13d02926-e322-410d-a637-b51ddaf05b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2\n",
    "ex2 = labeled_pirs.sample(n=1)\n",
    "ex2_text = ex2['Text']\n",
    "ex2_text = \"\".join(ex2_text)\n",
    "ex2_as = ex2['Actions_Strategies']\n",
    "ex2_as = ex2_as.to_csv(header = None, index=False)\n",
    "ex2_as = ex2_as.split('\\n')\n",
    "\n",
    "ex2_as = ','.join(ex2_as)\n",
    "ex2_as = ex2_as.replace(',,',',')\n",
    "ex2_as = ex2_as[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5fcf9e2-33b2-4c2f-b799-b591be999548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3\n",
    "ex3 = labeled_pirs.sample(n=1)\n",
    "ex3_text = ex3['Text']\n",
    "ex3_text = \"\".join(ex3_text)\n",
    "ex3_as = ex3['Actions_Strategies']\n",
    "ex3_as = ex3_as.to_csv(header = None, index=False)\n",
    "ex3_as = ex3_as.split('\\n')\n",
    "\n",
    "ex3_as = ','.join(ex3_as)\n",
    "ex3_as = ex3_as.replace(',,',',')\n",
    "ex3_as = ex3_as[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4632eedb-c4ff-4178-87c5-6e8b4f5162ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 4\n",
    "ex4 = labeled_pirs.sample(n=1)\n",
    "ex4_text = ex4['Text']\n",
    "ex4_text = \"\".join(ex4_text)\n",
    "ex4_as = ex4['Actions_Strategies']\n",
    "ex4_as = ex4_as.to_csv(header = None, index=False)\n",
    "ex4_as = ex4_as.split('\\n')\n",
    "\n",
    "ex4_as = ','.join(ex4_as)\n",
    "ex4_as = ex4_as.replace(',,',',')\n",
    "ex4_as = ex4_as[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2a9fb14-9c75-4943-a25d-515e175705a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5\n",
    "ex5 = labeled_pirs.sample(n=1)\n",
    "ex5_text = ex5['Text']\n",
    "ex5_text = \"\".join(ex5_text)\n",
    "ex5_as = ex5['Actions_Strategies']\n",
    "ex5_as = ex5_as.to_csv(header = None, index=False)\n",
    "ex5_as = ex5_as.split('\\n')\n",
    "\n",
    "ex5_as = ','.join(ex5_as)\n",
    "ex5_as = ex5_as.replace(',,',',')\n",
    "ex5_as = ex5_as[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f2f2f5-f21b-4992-94fa-8bc4377ec04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt template\n",
    "\n",
    "# Create our examples\n",
    "\n",
    "examples = [ \n",
    "    \n",
    "       { \"text\": ex1_text,\n",
    "        \n",
    "         \"Actions_Strategies\": ex1_as},\n",
    "       \n",
    "       { \"text\": ex2_text,\n",
    "        \n",
    "         \"Actions_Strategies\": ex2_as},\n",
    "       \n",
    "       { \"text\": ex3_text,\n",
    "        \n",
    "         \"Actions_Strategies\": ex3_as},\n",
    "       \n",
    "       { \"text\": ex4_text,\n",
    "        \n",
    "         \"Actions_Strategies\": ex4_as},\n",
    "       \n",
    "       { \"text\": ex5_text,\n",
    "        \n",
    "         \"Actions_Strategies\": ex5_as}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "369120a3-c47b-489f-89fc-c07cb2d590b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_template = \"\"\"\n",
    "\n",
    "Text: {text}\n",
    "Labels: {Actions_Strategies}\n",
    "\"\"\"\n",
    "\n",
    "# Create a few-shot prompt example from above template\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    \n",
    "    input_variables = [\"text\",\"Actions_Strategies\"],\n",
    "    template = example_template\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e77dc9-68ac-4b46-a9db-473619bbed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now break our previous prompt into a prefix and uuffix \n",
    "# the prefix is our instructions\n",
    "\n",
    "prefix = \"\"\" The following is an instruction for labeling Hospital Incident Reports (HIR) Text into categories of actions and strategies. \n",
    "\n",
    "A hospital incident report text is a document used to record unexpected events or accidents in a hospital, with the aim of improving patient safety and healthcare quality. \n",
    "\n",
    "The definition of actions and strategies in a HIR Text is refer to the procedures and interventions carried out in response to an incident in order to address the incident, ensure patient safety, reduce risks, and enhance overall care. With the definition of actions and strategies, please categorize the HIR Text into actions and strategies through the next steps: \n",
    "\n",
    "1. Start by thoroughly reading each Text to gain a comprehensive understanding of the actions or strategies detailed within it.\n",
    "\n",
    "2. Identify the specific actions or strategies mentioned in the Text that were either implemented or proposed to address the incident.\n",
    "\n",
    "3. In the below, you will be provided with five examples. Each example contains a Text and Labels, the corresponding categories representing actions or strategies in the Text. If there were no actions or strategies in the Text, then the Labels would be None. \n",
    "\n",
    "\n",
    "Here are the five examples:\n",
    "\n",
    "### BEGIN EXAMPLES \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40bad270-3d28-49f5-82d3-f831e54065aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the suffix our user input and output indicator\n",
    "\n",
    "suffix = \"\"\"\n",
    "\n",
    "### END EXAMPLES\n",
    "\n",
    "Based on the five examples given above, please label the following Text as actions and strategies. Your answer is not just to sort the text into the existing categories we talked about. You also need to come up with new categories that fit the actions and strategies mentioned in the following text.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f71c2f50-bf05-498e-b2cf-ab88ad326c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create the few shot promt template\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    \n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix = prefix,\n",
    "    suffix = suffix,\n",
    "    input_variables =[\"text\"],\n",
    "    example_separator =\"\\n\\n\"\n",
    "    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5daee928-dbb1-4593-8dc1-60a8bd9f11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the unlabeled text \n",
    "\n",
    "unlabeled_pir = PIRs_unlabeled['Text']\n",
    "\n",
    "unlabeled_pir_examples = unlabeled_pir.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4a26337-3b1a-40d0-9f26-7abc51d022da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The following is an instruction for labeling Hospital Incident Reports (HIR) Text into categories of actions and strategies. \n",
      "\n",
      "A hospital incident report text is a document used to record unexpected events or accidents in a hospital, with the aim of improving patient safety and healthcare quality. \n",
      "\n",
      "The definition of actions and strategies in a HIR Text is refer to the procedures and interventions carried out in response to an incident in order to address the incident, ensure patient safety, reduce risks, and enhance overall care. With the definition of actions and strategies, please categorize the HIR Text into actions and strategies through the next steps: \n",
      "\n",
      "1. Start by thoroughly reading each Text to gain a comprehensive understanding of the actions or strategies detailed within it.\n",
      "\n",
      "2. Identify the specific actions or strategies mentioned in the Text that were either implemented or proposed to address the incident.\n",
      "\n",
      "3. In the below, you will be provided with five examples. Each example contains a Text and Labels, the corresponding categories representing actions or strategies in the Text. If there were no actions or strategies in the Text, then the Labels would be None. \n",
      "\n",
      "\n",
      "Here are the five examples:\n",
      "\n",
      "### BEGIN EXAMPLES \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Text: [[DATE]:40:42 the reporter] pt had arrived on the unit at 1240 on [DATE]. EKG electrodes, leads, and heart monitor were attached to pt., but when [PERSONALNAME] RN arrived pt was not showing up on the telemetry monitor and was also showing up as \"unknown.\" there was no telemetry monitoring of the patient all day. [PERSONALNAME] RN put new batteries in the telemetry monitor and turned it on. monitor room was notified of what happened and a face sheet was faxed to them so they would have the patient's information. ..\n",
      "Labels: \"Use resources of supplies/orders,Communication of Staff notified,Record/Observe\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Text: Pt is a bilateral AKA with prostheses. Pt was ambulating without device, with CGA and second person for safety. Pt waved with a large movement to another gym occupant and lost balance when bringing her arm back down, therapists unable to prevent fall forward. Pt not injured and transferred from floor to motorized chair with min assist. Pt declined further intervention.\n",
      "Labels: \"Suggest/Prescribe,Patient maNonegement of Staff,Use resources of Supplies/Orders\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Text: [[DATE]:[DATE]:35 the reporter] Patient was completed with preop. Afterwards Dr. [PERSONALNAME] wrote orders for patient to receive a scopolamine patch prior to patient going to the OR. This was delayed due to patient already being completed in preop...\n",
      "Labels: Suggest/Prescribe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Text: Pt eloped with an IV still intact. [PERSONALNAME] was called to escort the pt back\n",
      "Labels: Communication of security notified\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Text: MD ordered for pt to stay and have repeat lab work done. Pt refused, and left AMA. AMA form completed.\n",
      "Labels: Record/Observe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### END EXAMPLES\n",
      "\n",
      "Based on the five examples given above, please label the following Text as actions and strategies. Your answer is not just to sort the text into the existing categories we talked about. You also need to come up with new categories that fit the actions and strategies mentioned in the following text.\n",
      "\n",
      "Text: pt was checked in to [PERSONALNAME] pediatric clinic at 1333 for 1400 appt time. pt was triaged and placed in room at 1340. mom came out to complain about wait time at least twice due to resident running behind and pt very fussy. mom was pregnant and diabetic and she and pt had not eaten lunch. nursing staff gave mom and pt snacks and drinks, second time mom spoke with attending who told her the resident would be with her next. mom could not wait any longer and left without being seen at 1506, appt was rescheduled for another day.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Print the prompt\n",
    "\n",
    "text =unlabeled_pir_examples\n",
    "\n",
    "prompt = few_shot_prompt_template.format(text=text)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f5b2b-51d0-4d88-adf9-e5b04815ea2c",
   "metadata": {},
   "source": [
    "The below section is calling the LLMs to label the metadata using the prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b8da6c3-a0bc-4741-aa7d-c8a43d8a1ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, using /scratch/dixizil/hf_cache for huggingface cache. Models will be stored there.\n",
      "Huggingface API key loaded.\n"
     ]
    }
   ],
   "source": [
    "# Set cache directory and load Huggingface api key\n",
    "\n",
    "import os\n",
    "\n",
    "username = os.getenv('USER')\n",
    "directory_path = os.path.join('/scratch',username)\n",
    "\n",
    "# Set Huggingface cache directory to be on scratch drive\n",
    "if os.path.exists(directory_path):\n",
    "    hf_cache_dir = os.path.join(directory_path,'hf_cache')\n",
    "    if not os.path.exists(hf_cache_dir):\n",
    "        os.mkdir(hf_cache_dir)\n",
    "    print(f\"Okay, using {hf_cache_dir} for huggingface cache. Models will be stored there.\")\n",
    "    assert os.path.exists(hf_cache_dir)\n",
    "    os.environ['TRANSFORMERS_CACHE'] = f'/scratch/{username}/hf_cache/'\n",
    "else:\n",
    "    error_message = f\"Are you sure you entered your username correctly? I couldn't find a directory {directory_path}.\"\n",
    "    raise FileNotFoundError(error_message)\n",
    "\n",
    "# Load Huggingface api key\n",
    "api_key_loc = os.path.join('/home', username, '.apikeys', 'huggingface_api_key.txt')\n",
    "\n",
    "if os.path.exists(api_key_loc):\n",
    "    print('Huggingface API key loaded.')\n",
    "else:\n",
    "    error_message = f'Huggingface API key not found. You need to get an HF API key from the HF website and store it at {api_key_loc}.\\n' \\\n",
    "                    'The API key will let you download models from Huggingface.'\n",
    "    raise FileNotFoundError(error_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b9857cd-0e2e-473a-9349-02f73da98c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6798cb4a-f435-43af-8079-e10c86c51723",
   "metadata": {},
   "source": [
    "Alpaca 30B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287dcc94-dfe1-4dc5-9059-5c8c6592eaa0",
   "metadata": {},
   "source": [
    "* VicUnlocked-alpaca-30B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc3505-a8c8-4520-a1d1-42cac3348808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Aeala/VicUnlocked-alpaca-30b\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Aeala/VicUnlocked-alpaca-30b\")\n",
    "\n",
    "print('Instantiating pipeline')\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    do_sample=True,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=2048,\n",
    "    temperature=1,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2)\n",
    "\n",
    "print('Instantiating HuggingFacePipeline')\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209d726-42c1-494d-a1c0-ec2eb83afdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model's output\n",
    "print(prompt + local_llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e2d3a-405c-4f46-8536-bec2ea7e2eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0908a62-7af3-4b38-9cc6-4975bd651732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a9bbe8-85d8-4278-a081-196e363494eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3460d7a-fcf0-4b42-8a6c-3b9aeb99560e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMS Environment",
   "language": "python",
   "name": "llms_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
