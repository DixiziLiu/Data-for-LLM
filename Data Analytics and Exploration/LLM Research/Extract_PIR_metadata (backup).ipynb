{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1765420-c0ed-44ba-9df7-46c3af36cd57",
   "metadata": {},
   "source": [
    "This notebook is for developing the code for extracting metadata from the Prisma incident report (PIR) data. The notebook:\n",
    "\n",
    "* Loads the full set of PIRs, both labeled and unlabeled\n",
    "* Separates the labeled from the unlabeled PIRs\n",
    "* Defines a function that takes as input a prompt template, a set of labeled PIRs, and an unlabeled PIR to create a few-shot learning (FSL) prompt\n",
    "* Defines a function that takes as input a prompt and a LLM, and returns the model's output\n",
    "* Defines a function that parses the model output to produce structured metadata\n",
    "* Saves the resulting structured metadata.\n",
    "\n",
    "This notebook is for developing that code; once it is developed, it should be put into one or several .py script(s) so that it can be run on the Cluster without having a Jupyter session open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71919392-78b9-4b81-b577-bc602d262626",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "#from utils.load_llm_model import prepare_to_load_model, load_model\n",
    "#import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31431dc-57dc-422c-a256-12d7b5a3c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unlabeled PIRs (full)\n",
    "\"\"\"\n",
    "In its final form, the unlabeled PIRs should be in the format of a pandas dataframe,\n",
    "where one column (titled 'text') is the PIR, and 'near_miss' and 'any_harm' each have a column.\n",
    "\"\"\"\n",
    "\n",
    "# Read the full PIRs\n",
    "\n",
    "PIRs_full = pd.read_excel(\"PIRS_FULL.xlsx\",usecols=['Near_Miss', 'Any_Harm', 'Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7ab86-ed0b-4243-bb31-d2b001905def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled PIRs\n",
    "\"\"\"\n",
    "In its final form, the labeled PIRs should be in the format of a pandas dataframe with four columns,\n",
    "where one column (titled 'text') is the PIR, and the other three columns are 'risks_challenges',\n",
    "'actions_strategies', and 'facilitators'.\n",
    "\"\"\"\n",
    "\n",
    "# Read the labeled PIRs\n",
    "\n",
    "PIRs_labeled = pd.read_excel(\"PIRS_LABELED.xlsx\", usecols=['Text', 'Risk_Challenge', 'Actions_Strategies', 'Facilitators'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2010a8b-843a-4e06-af66-2d270c37ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labeled from unlabeled PIRs\n",
    "\"\"\"\n",
    "PIRs appearing in the labeled data should be dropped from the unlabeled data set.\n",
    "\"\"\"\n",
    "\n",
    "df = pd.merge(PIRs_full, PIRs_labeled, on =[\"Text\"], how = \"outer\", indicator = True)\n",
    "\n",
    "df2 = df.loc[df[\"_merge\"] == \"left_only\"].drop(\"_merge\", axis=1)\n",
    "\n",
    "PIRs_unlabeled = df2.drop(columns=['Risk_Challenge', 'Facilitators', 'Near_Miss', 'Any_Harm'])\n",
    "\n",
    "#PIRs_unlabeled['Actions_Strategies'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39566ba7-ef6d-4415-9a67-a7963f956c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the prompt template text to a string\n",
    "with open(\"PIR_Prompt_AS.txt\",\"r\") as file:\n",
    "    template = file.read()\n",
    "\n",
    "# Now the variable \"template\" contains the contents of PIR_Prompt_AS.txt as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946b10b-ae6c-4507-a5db-a87707755284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: create FSL prompt\n",
    "def create_fsl_prompt(labeled_pirs, unlabeled_pir,template=template):\n",
    "    \n",
    "    # Get the actions/strategies labeled PIRs into a dictionary\n",
    "    labeled_pirs = PIRs_labeled[['Text','Actions_Strategies']]\n",
    "    \n",
    "    # Randomly select labeled PIRs\n",
    "    labeled_pirs_examples = random.sample(labeled_pirs, 5)\n",
    "    \n",
    "    # Unlabeled PIRs\n",
    "    \n",
    "    unlabeled_pir = PIRs_unlabeled[['Text','Actions_Strategies']]\n",
    "    \n",
    "    # Just select one unlabeled PIRs for test\n",
    "    \n",
    "    unlabeled_pir = unlabeled_pir.iloc[0]\n",
    "    \n",
    "    unlabeled_pir=unlabeled_pir.to_string()\n",
    "    \n",
    "    \n",
    "    # Construct the final prompt\n",
    "    \n",
    "    prompt_template = PromptTemplate(template=template, \n",
    "                                     input_variables=[\"examples\",\"text\"])\n",
    "    \n",
    "    # Integrate randomly selected labeled PIRs into prompt templates\n",
    "    \n",
    "    labeled_prompt_input_dict = {'examples': labeled_pirs_examples}\n",
    "    \n",
    "    unlabeled_prompt_input_dict = {'text':unlabeled_pir}\n",
    "    \n",
    "    # Prompts\n",
    "    \n",
    "    labeled_prompt = prompt_template.format(**labeled_prompt_input_dict)\n",
    "    \n",
    "    unlabeled_prompt = prompt_template.format(**unlabeled_prompt_input_dict)\n",
    "    \n",
    "    # Convert into a dict\n",
    "    \n",
    "    prompts = {'labeled ':{'prompt':labeled_prompt},\n",
    "               'unlabeled':{'prompt':unlabeled_prompt}}\n",
    "    \n",
    "    return prompts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a481b-b01f-4269-8648-6effc4676f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#def get_model_output(model, prompt:str):\n",
    "    \"\"\"\n",
    "    Return a model's output given a particular prompt.\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    #pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8c3a1-9b41-4280-b389-022f6824f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_output(pir, category, output):\n",
    "    \"\"\"\n",
    "    Parse a model's text output in order to extract structured metadata from it.\n",
    "\n",
    "    Args:\n",
    "        pir (str): The text of the PIR that the model was asked to generate metadata about.\n",
    "        category (str): The category of metadata the model was asked to generate (e.g. 'risk_challenge')\n",
    "        output (str): The model's text output.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\"text\":pir, category:list_of_labels}\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
